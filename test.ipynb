{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3237050/1349107445.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load('/remote-home/share/lisj/Workspace/SOTA_NAS/datasets/core/MUSK-feature/1819360.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bag_feats': tensor([[-0.0267, -0.0053, -0.0062,  ..., -0.0027, -0.0048,  0.0004],\n",
       "         [-0.0008,  0.0065, -0.0083,  ...,  0.0024,  0.0259, -0.0050],\n",
       "         [ 0.0104,  0.0091,  0.0120,  ...,  0.0038,  0.0017,  0.0038],\n",
       "         ...,\n",
       "         [ 0.0150,  0.0014, -0.0282,  ...,  0.0205, -0.0133, -0.0228],\n",
       "         [-0.0045,  0.0157, -0.0044,  ..., -0.0003,  0.0137, -0.0144],\n",
       "         [-0.0013,  0.0140,  0.0044,  ..., -0.0110,  0.0142, -0.0222]],\n",
       "        dtype=torch.float16),\n",
       " 'coords': tensor([[146, 315],\n",
       "         [146, 316],\n",
       "         [146, 317],\n",
       "         ...,\n",
       "         [289, 383],\n",
       "         [289, 384],\n",
       "         [289, 385]], dtype=torch.int32)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.load('/remote-home/share/lisj/Workspace/SOTA_NAS/datasets/core/MUSK-feature/1819360.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件加载成功！\n",
      "\n",
      "加载的数据类型: <class 'dict'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LoadedLoggers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loaded_epoch_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m加载的数据类型:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m(loaded_epoch_metrics))\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loaded_epoch_metrics, \u001b[43mLoadedLoggers\u001b[49m):\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m成功加载 LoadedLoggers 对象。\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# LoadedLoggers 对象可能有一个名为 df 的属性，其中存储了DataFrame\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LoadedLoggers' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd # 可选，但推荐用于数据分析和展示\n",
    "import numpy as np\n",
    "from contrast_study.FOCUS-main.utils.utils import LoadedLoggers\n",
    "# 定义您的 .pkl 文件路径\n",
    "# 请将此路径替换为您实际的 .pkl 文件路径\n",
    "pkl_file_path = \"/remote-home/share/lisj/Workspace/SOTA_NAS/BMW/contrast_study/FOCUS-main/results/FOCUS/musk/task_musk_single_run_test_s1/run_0_detailed_results.pkl\" \n",
    "# 注意：上面的 'task_musk_single_run_test_s1' 和 'run_0_detailed_results.pkl' 中的数字可能需要根据您的实际文件名调整\n",
    "\n",
    "# 加载 .pkl 文件\n",
    "try:\n",
    "    with open(pkl_file_path, 'rb') as f:\n",
    "        # loaded_results 现在应该是 LoadedLoggers 的一个实例\n",
    "        loaded_epoch_metrics = pickle.load(f) \n",
    "    print(\"文件加载成功！\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误: 文件未找到，请检查路径 '{pkl_file_path}' 是否正确。\")\n",
    "    loaded_epoch_metrics = None\n",
    "except Exception as e:\n",
    "    print(f\"加载文件时出错: {e}\")\n",
    "    loaded_epoch_metrics = None\n",
    "\n",
    "# 查看加载的数据\n",
    "if loaded_epoch_metrics is not None:\n",
    "    print(\"\\n加载的数据类型:\", type(loaded_epoch_metrics))\n",
    "\n",
    "    if isinstance(loaded_epoch_metrics, LoadedLoggers):\n",
    "        print(\"\\n成功加载 LoadedLoggers 对象。\")\n",
    "\n",
    "        # LoadedLoggers 对象可能有一个名为 df 的属性，其中存储了DataFrame\n",
    "        if hasattr(loaded_epoch_metrics, 'df') and isinstance(loaded_epoch_metrics.df, pd.DataFrame):\n",
    "            print(\"\\nEpoch 级别的指标 (DataFrame):\")\n",
    "            print(loaded_epoch_metrics.df)\n",
    "\n",
    "            # 您可以进一步分析这个 DataFrame\n",
    "            # 例如，打印列名：\n",
    "            print(\"\\nDataFrame 列名:\", loaded_epoch_metrics.df.columns.tolist())\n",
    "            # 例如，打印最后几轮的验证AUC：\n",
    "            if 'val_auc' in loaded_epoch_metrics.df.columns:\n",
    "                print(\"\\n最后5轮的验证AUC:\")\n",
    "                print(loaded_epoch_metrics.df['val_auc'].tail())\n",
    "        else:\n",
    "            print(\"\\nLoadedLoggers 对象中未找到预期的 'df' DataFrame。检查其属性：\")\n",
    "            # 打印 LoadedLoggers 对象的属性，看哪些属性存储了 epoch 数据\n",
    "            if hasattr(loaded_epoch_metrics, 'epoch_loss_log'):\n",
    "                print(\"  训练损失 (epoch_loss_log):\", loaded_epoch_metrics.epoch_loss_log)\n",
    "            if hasattr(loaded_epoch_metrics, 'val_loss_log'):\n",
    "                print(\"  验证损失 (val_loss_log):\", loaded_epoch_metrics.val_loss_log)\n",
    "            if hasattr(loaded_epoch_metrics, 'val_auc_log'):\n",
    "                print(\"  验证AUC (val_auc_log):\", loaded_epoch_metrics.val_auc_log)\n",
    "            # ... 可以添加其他日志列表的打印\n",
    "    else:\n",
    "        # 如果不是 LoadedLoggers，按之前的方式处理 (尽管根据 core_utils.py 这不应该发生)\n",
    "        print(\"加载的数据不是预期的 LoadedLoggers 类型。\")\n",
    "        # (这里可以保留之前处理普通字典的代码作为后备，但理论上不需要了)\n",
    "        if isinstance(loaded_epoch_metrics, dict):\n",
    "             print(f\"\\n加载的字典中共有 {len(loaded_epoch_metrics)} 个条目。\")\n",
    "             # ... (之前处理slide_id字典的逻辑) ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
